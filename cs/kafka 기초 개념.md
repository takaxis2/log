## Apache Kafka란 무엇일까요?

Apache Kafka는 실시간으로 기록 스트림을 게시, 구독, 저장 및 처리할 수 있는 분산형 [데이터 스트리밍](https://www.redhat.com/ko/topics/integration/what-is-streaming-data) 플랫폼입니다. 

여러 소스에서 데이터 스트림을 처리하고 여러 사용자에게 전달하도록 설계되었습니다. 간단히 말해 A지점에서 B지점까지 이동하는 것뿐만 아니라 A지점에서 Z지점을 비롯해 필요한 모든 곳에서 대규모 데이터를 동시에 이동할 수 있습니다.

Apache Kafka는 전통적인 엔터프라이즈 메시징 시스템의 대안입니다. 하루에 1조 4천억 건의 메시지를 처리하기 위해 LinkedIn이 개발한 내부 시스템으로 시작했으나, 현재 이는 다양한 기업의 요구 사항을 지원하는 애플리케이션을 갖춘 오픈소스 데이터 스트리밍 솔루션이 되었습니다.

## Apache Kafka와 비동기식 통합

[마이크로서비스](https://www.redhat.com/ko/topics/microservices)는 개발 환경을 바꾸어 놓았습니다. 

공유 데이터베이스 계층과 같은 종속성을 줄여 개발자들이 더욱 민첩하게 작업을 수행하도록 해줍니다. 그러나 개발자가 구축 중인 분산형 애플리케이션이 데이터를 공유하려면 특정한 유형의 통합이 필요합니다. 널리 사용되는 통합 옵션으로 동기식 방법이 있는데, 이는 서로 다른 사용자 간 데이터를 공유하는 데 애플리케이션 프로그래밍 인터페이스(API)를 활용합니다.

또 다른 통합 옵션으로는 중간 스토어에서 데이터를 복제하는 비동기식 방법이 있습니다. 

Apache Kafka는 바로 이런 맥락에 등장하는 솔루션으로, 다른 개발팀의 데이터를 스트리밍하여 데이터 스토어를 채우면 해당 데이터를 여러 팀과 이들의 애플리케이션 간에 공유할 수 있게 됩니다.

마이크로서비스 팀의 통합 요구 사항은 전통적인 워터폴(waterfall) 개발팀과는 다릅니다. 이들 팀은 다음과 같은 3가지 기반 기능을 필요로 합니다.

1. [**분산형 통합**](https://www.redhat.com/ko/topics/integration)**: 필요한 경우 지속적으로 배포할 수 있는 경량의 패턴 기반 통합으로, 중앙집중식 ESB 유형 배포의 제약을 받지 않습니다.**  
     
2. [**API**](https://www.redhat.com/ko/topics/api)**: 파트너, 고객 및 개발자로 이루어진 에코시스템을 구현하는 API 기반 서비스로, 신뢰성과 수익성을 갖춘 유용한 활용 방안을 제공합니다.**  
     
3. [**컨테이너**](https://www.redhat.com/ko/topics/containers)**:** [**클라우드 네이티브**](https://www.redhat.com/ko/topics/cloud-native-apps) **방식의 커넥티드 애플리케이션을 개발, 관리 및 확장하는 플랫폼입니다. 컨테이너는 개별 배포 방식으로** [**DevOps**](https://www.redhat.com/ko/topics/devops) **프로세스에 포함되면서, 즉시 사용 가능한 클러스터링에 의해 지원되는 린(lean) 아티팩트 개발을 사용할 수 있도록 함으로써 고가용성을 보장합니다.**

## Apache Kafka 구조
![[Pasted image 20251118013749.png]]
## 용어 정리

- **KafkaCluster**: 카프카 브로커들의 모임. Kafka는 확장성과 고가용성을 위해서 broker들이 클러스터로 구성됩니다.
- **Broker:** 각각의 카프카 서버
- **ZooKeeper:** 카프카 클로스터 정보 및 분산처리 관리 등 메타데이터 저장. 카프카를 띄우기 위해 반드시 실행되어야 합니다.
- **Producer:** 메시지(이벤트)를 발행하여 생산하는 주체 (클라우드 네이티브 애플리케이션)
- **Consumer:** 메시지(이벤트)를 구독하여 소비하는 주체 (클라우드 네이티브 애플리케이션)