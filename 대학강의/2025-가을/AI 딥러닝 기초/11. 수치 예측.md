## 핵심 요약

본 문서는 AI 딥러닝을 활용하여 연속적인 수치를 예측하는 회귀(Regression) 문제의 핵심 원리와 실행 방법론을 종합적으로 다룬다. 수치 예측은 주택 가격, 주식 가격 등과 같은 연속적인 값을 목표로 하며, 딥러닝 모델은 입력 변수와 결과 값 사이의 복잡한 비선형 관계를 학습한다.

성공적인 모델 구축을 위해서는 데이터 전처리가 필수적이다. 결측치는 평균값 등으로 대체(`fillna()`)하거나 제거(`dropna()`)하고, 문자열 형태의 카테고리 변수는 원-핫 인코딩(`get_dummies()`)을 통해 숫자 형태로 변환해야 한다. 또한, 각 독립변수의 값 범위를 유사한 수준으로 맞추는 표준화(Standardization) 과정은 모델의 학습 수렴 속도를 높이고 예측 성능을 최적화하는 데 핵심적인 역할을 한다.

모델링에 앞서, 상관 분석(`corr()`, `pairplot()`)을 통해 변수 간의 선형 관계를 파악하고, 예측 목표와 관련성이 높은 주요 변수를 식별할 수 있다. Keras를 사용한 심층 신경망(DNN) 모델은 일반적으로 은닉층에 `relu` 활성화 함수를 적용하고, 회귀 문제의 출력층에는 특정 활성화 함수 없이 선형 계산 결과를 그대로 출력하도록 설계한다. 모델은 평균 제곱 오차(MSE)와 같은 손실 함수와 'adam'과 같은 최적화 알고리즘으로 컴파일하여 학습을 준비한다.

마지막으로, 모델의 성능은 회귀 문제에 특화된 지표를 통해 객관적으로 평가된다. 주요 평가지표로는 평균 제곱 오차(MSE), 평균 절대 오차(MAE), 결정계수(R²) 등이 있으며, 이는 혼동 행렬(Confusion Matrix)이나 F1-Score를 사용하는 분류 문제의 평가 방식과는 명확히 구분된다.

--------------------------------------------------------------------------------

## 1. 수치 예측 문제의 이해

### 1.1. 정의 및 목표

수치 예측은 연속적인 값을 예측하는 **회귀(Regression)** 문제의 한 유형이다. 주어진 입력 데이터(피처)를 바탕으로 주택 가격, 주식 가격, 온도, 매출액 등과 같은 연속적인 출력 값을 예측하는 것을 목표로 한다.

딥러닝 모델은 입력 피처와 출력 값 사이의 복잡하고 비선형적인 관계를 학습하여 예측 정확도를 높인다. 모델 학습의 궁극적인 목표는 예측 값과 실제 값 사이의 차이, 즉 오차를 최소화하는 것이다. 이 오차는 손실 함수(Loss Function)를 통해 측정되며, 대표적으로 평균제곱오차(MSE)와 평균절대오차(MAE)가 사용된다.

### 1.2. 주요 적용 사례: 주택 가격 예측

수치 예측의 대표적인 사례는 다양한 요인을 기반으로 주택의 시장 가치를 예측하는 것이다.

- **입력 피처:** 주택의 크기, 위치, 방의 개수, 건축 연도, 주변 환경 등 주택 가격에 영향을 미치는 80여 개의 다양한 속성.
- **출력 값:** 예측하고자 하는 주택의 가격 (연속적인 실수 값).
- **모델 학습:** 주어진 입력 피처와 실제 주택 가격 데이터 간의 관계를 학습하여 최적의 가중치를 찾는다.
- **예측:** 학습된 모델에 새로운 주택 정보를 입력하면 해당 주택의 예상 가격을 출력한다.

## 2. 데이터 전처리 및 준비

모델의 성능을 극대화하기 위해 원본 데이터를 학습에 적합한 형태로 가공하는 전처리 과정은 필수적이다.

### 2.1. 결측치 처리

데이터셋에 누락된 값(결측치)이 있는지 확인하고 이를 적절히 처리해야 한다. Pandas 라이브러리의 함수를 주로 사용한다.

|   |   |   |
|---|---|---|
|함수|설명|사용 예시|
|`isnull().sum()`|각 열(속성)별 결측치의 개수를 계산한다.|`df.isnull().sum().sort_values()`|
|`fillna()`|결측치를 특정 값으로 채운다. 평균값, 중앙값, 0 등으로 대체할 수 있다.|`df.fillna(df.mean())`|
|`dropna()`|결측치가 포함된 행 또는 열을 제거한다.|`dropna(how='any')`|

### 2.2. 카테고리 변수 변환: 원-핫 인코딩

'주거 유형'과 같이 문자열로 구성된 범주형(카테고리) 변수는 모델이 이해할 수 있도록 숫자 형태로 변환해야 한다. 이때 **원-핫 인코딩(One-Hot Encoding)**이 널리 사용된다. 이는 각 범주를 새로운 열로 만들고, 해당하는 범주에만 1(hot)을, 나머지는 0을 부여하는 방식이다.

- `**get_dummies()**` **함수:** Pandas의 이 함수는 카테고리 변수를 원-핫 인코딩 형태로 손쉽게 변환해 준다.

### 2.3. 데이터 표준화 (Standardization)

서로 다른 독립변수들이 각기 다른 값의 범위(scale)를 가질 경우, 모델의 학습 속도가 저하되거나 최적의 해를 찾는 데 어려움을 겪을 수 있다. **표준화**는 모든 데이터의 평균을 0, 표준편차를 1인 분포로 변환하여 이러한 문제를 해결하고 모델의 예측 성능을 높인다.

- **목적:** 독립변수들의 규모 차이로 인한 학습 속도 저하 방지.
- **방법:** 각 데이터 값에서 해당 변수의 평균을 뺀 후, 표준편차로 나눈다.
- **별칭:** 표준화 스칼라(Standard Scaler), Z-스코어 정규화(Z-score normalization).
- **효과:** 데이터 분포가 가우시안 분포를 따를 때 특히 유용하다.

## 3. 상관 분석을 통한 데이터 탐색

모델링에 사용할 변수를 선택하거나 데이터의 특성을 이해하기 위해 변수 간의 관계를 분석한다.

### 3.1. 상관관계 계산

**피어슨 상관계수(Pearson Correlation Coefficient)**는 두 변수 간의 선형 관계의 강도와 방향을 측정하는 지표로, -1에서 1 사이의 값을 가진다.

- **1:** 완벽한 양의 선형 관계 (하나가 증가하면 다른 하나도 비례하여 증가)
- **-1:** 완벽한 음의 선형 관계 (하나가 증가하면 다른 하나는 비례하여 감소)
- **0:** 선형 관계 없음

Pandas의 `corr()` 함수를 사용하여 데이터프레임 내 모든 변수 쌍 간의 상관계수를 계산할 수 있다. 이를 통해 목표 변수(예: 집 값)와 상관관계가 높은 주요 변수들을 식별할 수 있다.

### 3.2. 상관도 시각화

`**pairplot()**` **함수** (seaborn 라이브러리)는 데이터셋 내 변수들 간의 관계를 한눈에 파악할 수 있도록 시각화한다.

- **산점도:** 각 변수 쌍에 대한 산점도를 그려 선형 관계를 시각적으로 확인한다.
- **히스토그램:** 대각선 위치에는 각 변수 자체의 분포를 히스토그램으로 표시한다.
- 이를 통해 변수 간 관계뿐만 아니라 각 변수의 분포 특성까지 동시에 파악할 수 있다.

## 4. 심층 신경망(DNN) 모델링

### 4.1. 모델 구조 설계

Keras 라이브러리의 `Sequential` API를 사용하여 층(Layer)을 순차적으로 쌓아 모델을 구성한다.

- **입력층:** 첫 번째 `Dense` 층에 `input_dim` 매개변수를 지정하여 입력 데이터의 차원(피처의 개수)을 정의한다. 이 층은 입력층과 첫 번째 은닉층의 역할을 겸한다.
- **은닉층:** `Dense` 층을 여러 개 추가하여 모델의 깊이를 조절한다.
    - **활성화 함수:** 은닉층에서는 주로 `**relu**` **(Rectified Linear Unit)** 함수가 사용된다. `relu`는 입력이 양수이면 그대로 출력하고 음수이면 0을 출력하여, 기울기 소멸(Vanishing Gradient) 문제를 완화하는 데 효과적이다.
- **출력층:**
    - 수치 예측(회귀) 문제에서는 예측해야 할 값이 1개이므로 뉴런의 개수를 1로 설정한다 (`Dense(1)`).
    - 별도의 활성화 함수를 지정하지 않아, 층의 선형 계산 결과를 그대로 출력값으로 사용한다. (참고: 이진 분류는 'sigmoid', 다중 분류는 'softmax' 사용)
- `**model.summary()**`**:** 생성된 모델의 각 층 구조, 출력 형태, 학습 파라미터(가중치와 바이어스) 수를 확인할 수 있다.

### 4.2. 모델 컴파일

설계된 모델의 학습 과정에 필요한 환경을 설정하는 단계이다. `model.compile()` 함수를 사용한다.

- `**loss**` **(손실 함수):** 모델의 예측 오차를 측정하는 기준으로, 회귀 문제에서는 주로 `'mean_squared_error'` (평균 제곱 오차)를 사용한다.
- `**optimizer**` **(최적화 알고리즘):** 손실 함수를 최소화하기 위해 모델의 가중치를 업데이트하는 방법. 일반적으로 `'adam'`이 우수한 성능을 보여 널리 사용된다.
- `**metrics**` **(성능 측정 지표):** 학습 및 검증 과정에서 모델의 성능을 모니터링하기 위한 지표. `'mape'` (평균 절대 오차율) 등을 설정할 수 있다.

### 4.3. 핵심 손실 함수 (Loss Function)

손실 함수는 모델의 예측값과 실제값의 차이를 계산하여 모델이 얼마나 틀렸는지를 정량화한다.

|   |   |   |   |   |
|---|---|---|---|---|
|모델 유형|손실 함수|약어|수식|설명|
|**회귀**|평균 제곱 오차|MSE|`1/n * Σ(y - ŷ)²`|오차의 제곱에 대한 평균. 오차가 클수록 패널티가 커짐.|
||평균 절대 오차|MAE|`1/n * Σ|y - ŷ|
||평균 절대 오차율|MAPE|`100/n * Σ|(y - ŷ)/y|
||평균 제곱근 오차|RMSE|`sqrt(MSE)`|MSE에 제곱근을 취해 실제 오차와 단위가 동일함.|
||평균 제곱 로그 오차|MSLE|`1/n * Σ(log(y+1) - log(ŷ+1))²`|큰 값의 오차 영향을 줄이고 싶을 때 사용.|
|**분류**|이진 교차 엔트로피|-|`-ylog(ŷ) – (1-y)log(1-ŷ)`|두 개의 클래스 중 하나를 예측하는 이진 분류에 사용.|
||범주형 교차 엔트로피|CCE|`-Σ y log(ŷ)`|세 개 이상의 클래스를 예측하는 다중 분류에 사용 (타깃이 원-핫 인코딩).|
||희소 범주형 교차 엔트로피|SCCE|-|CCE와 동일하나, 타깃값이 정수 형태일 때 사용.|

`_y_`_: 실제값,_ `_ŷ_`_: 예측값_

## 5. 모델 성능 평가

구축된 모델이 실용 가능한 수준인지 판단하기 위해 객관적인 평가지표로 성능을 측정한다.

### 5.1. 회귀 모델 평가 지표

회귀 모델은 예측값과 실제값의 오차를 기반으로 성능을 평가한다.

|   |   |
|---|---|
|평가지표|정의 및 설명|
|**평균 제곱 오차 (MSE)**|실제값과 예측값의 차이를 제곱하여 평균 낸 값.|
|**평균 절대 오차 (MAE)**|실제값과 예측값의 차이의 절댓값을 평균 낸 값.|
|**평균 절대 오차율 (MAPE)**|오차를 백분율로 계산하여 오차의 크기를 직관적으로 파악 가능.|
|**평균 제곱근 오차 (RMSE)**|MSE에 제곱근을 취한 값으로, 모델의 정밀도를 표현하는 데 적합.|
|**결정계수 (R²)**|모델이 데이터의 변동성을 얼마나 잘 설명하는지를 나타내는 척도. 0과 1 사이의 값을 가지며, 1에 가까울수록 설명력이 높다. `R² = 1 - (SSE / SST)`로 계산된다. (SST: 총제곱합, SSE: 오차제곱합)|

### 5.2. 분류 모델 평가 지표 (참고)

분류 모델의 평가는 회귀 모델과 다른 지표를 사용한다. 이는 주로 **혼동 행렬(Confusion Matrix)**에 기반한다.

- **혼동 행렬:** 모델의 예측 범주와 실제 범주를 교차표 형태로 정리한 행렬. (TP, TN, FP, FN)
- **주요 지표:**
    - **정확도(Accuracy):** 전체 데이터 중 정확하게 예측한 비율.
    - **정밀도(Precision):** Positive로 예측한 것 중 실제 Positive인 비율.
    - **재현율(Recall):** 실제 Positive인 것 중 모델이 Positive로 예측한 비율.
    - **F1-Score:** 정밀도와 재현율의 조화 평균으로, 두 지표가 모두 중요할 때 사용.
    - **ROC Curve & AUC:** 모델의 분류 성능을 시각적으로 나타내는 곡선과 그 아래 면적.