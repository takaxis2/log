
## 요약

본 문서는 다중 분류 문제의 정의부터 심층 신경망(DNN)을 활용한 해결 방법까지의 핵심 개념을 종합적으로 다룬다. 주요 내용은 패션 MNIST 데이터셋을 활용한 다중 분류 문제의 이해, 분류 모델의 핵심적인 오차 함수(교차 엔트로피), 그리고 인공 신경망과 심층 신경망의 구조 정의 및 컴파일 과정이다.

다중 분류는 3개 이상의 클래스 중 하나를 예측하는 문제로, 이진 분류와는 다른 접근 방식을 요구한다. 패션 MNIST 데이터셋은 이러한 다중 분류 실습을 위한 표준 데이터로, 10종류의 패션 아이템에 대한 28x28 픽셀 이미지로 구성된다.

분류 모델의 성능을 결정하는 핵심 요소는 활성화 함수와 손실 함수이다. 이진 분류에서는 시그모이드 함수를 사용하여 출력을 0과 1 사이의 확률값으로 변환하고, 다중 분류에서는 소프트맥스 함수를 통해 모든 클래스에 대한 확률 분포를 구한다. 손실 함수로는 로그 함수에 기반한 교차 엔트로피 오차가 사용되며, 타깃값의 형태에 따라 **범주형 교차 엔트로피(원-핫 인코딩 필요)**와 **희소 범주형 교차 엔트로피(정수 형태 사용 가능)**로 나뉜다.

신경망 모델 구축 시, `Flatten` 클래스는 다차원 입력 데이터(이미지 등)를 1차원 배열로 변환하는 역할을 하며, `Dense` 클래스는 완전 연결층을 구성한다. 케라스(Keras)는 `Sequential` 클래스를 통해 이러한 층들을 순차적으로 쌓아 모델을 유연하게 정의하는 여러 방법을 제공한다. 마지막으로, `model.compile()` 메서드를 통해 손실 함수, 최적화기, 평가 지표를 설정하여 모델의 학습 과정을 정의한다.

## 1. 다중 분류 문제의 이해

### 다중 분류(Multi-class Classification) 정의

다중 분류란 3개 이상의 선택지(클래스) 중에서 하나를 정답으로 고르는 분류 문제를 의미한다. 이는 '생존/사망'과 같이 두 가지 중 하나를 선택하는 이항 분류(Binary Classification)와는 접근 방식에서 차이가 있다.

- **이항 분류 예시**: 폐암 환자의 1년 후 생존 여부 예측 (생존/사망)
- **다중 분류 예시**:
    - 아이리스 품종 예측 (Setosa, Versicolor, Virginica 3종)
    - 패션 아이템 분류 예측 (티셔츠, 바지, 신발 등 10종)

### 패션 MNIST 데이터셋 분석

패션 MNIST 데이터셋은 손으로 쓴 숫자 이미지로 구성된 기존의 MNIST 데이터셋과 동일한 크기 및 형식을 가지지만, 숫자 대신 10종류의 패션 아이템 이미지로 이루어져 있다. 이는 다중 분류 문제 해결을 위한 대표적인 실습용 데이터셋이다.

- **입력 (속성)**: 28x28 픽셀 크기의 흑백 패션 아이템 이미지. 각 픽셀은 0(검은색)부터 255(흰색)까지의 정수값을 가진다. 인공 신경망에 입력하기 위해 이 2차원 배열(28x28)은 `reshape()` 메서드 등을 통해 784개의 요소를 가진 1차원 배열로 변환된다.
- **출력 (타깃)**: 0부터 9까지의 정수로 표현된 10개의 클래스(레이블). 각 숫자는 특정 패션 아이템 종류에 해당한다.

|   |   |
|---|---|
|레이블 (정수)|패션 아이템 종류|
|0|T-shirt/top|
|1|Trouser|
|2|Pullover|
|3|Dress|
|4|Coat|
|5|Sandal|
|6|Shirt|
|7|Sneaker|
|8|Bag|
|9|Ankle boot|

## 2. 분류 모델의 오차 함수와 핵심 함수

분류 모델, 특히 신경망 모델의 성능은 예측값과 실제값의 차이(오차)를 어떻게 측정하고 줄여나가는지에 달려있다. 이를 위해 활성화 함수와 오차 함수(손실 함수)가 핵심적인 역할을 수행한다.

### 활성화 함수

#### 시그모이드 함수 (Sigmoid Function)

시그모이드 함수는 S자 형태의 곡선을 그리는 함수로, 입력값을 0과 1 사이의 값으로 변환한다. 이러한 특성 때문에 특정 범주에 속할 확률을 예측하는 **이진 분류** 문제의 출력층 활성화 함수로 주로 사용된다.

- **특징**:
    - 로지스틱 회귀의 기반이 되는 함수이다.
    - 자연 상수 `e`를 밑으로 하는 지수 함수를 포함한 식으로 정의된다.
    - 입력값(x)이 클수록 출력값은 1에 가까워지고, 작을수록 0에 가까워진다.

#### 소프트맥스 함수 (Softmax Function)

소프트맥스 함수는 **다중 분류** 문제의 출력층에 적용되는 활성화 함수이다. K개의 클래스에 대한 예측값을 입력받아, 각 클래스에 속할 확률을 나타내는 K개의 값을 출력한다.

- **특징**:
    - 출력된 모든 값의 총합은 항상 1이므로 확률 분포로 해석할 수 있다.
    - 입력값에 지수 함수(exp)를 적용하여 정규화한다. 이를 통해 가장 큰 입력값을 더욱 부각시켜 다른 값들과의 차이를 증폭시키는 효과가 있다.
    - 수식: `softmax(xi) = exp(xi) / Σ exp(xj)`

### 오차(손실) 함수

#### 이진 교차 엔트로피 (Binary Cross-Entropy)

이진 분류 문제에서 모델의 예측값(h)과 실제값(y) 사이의 오차를 측정하기 위해 사용된다. 이는 로그 함수의 특성을 활용한다.

- **원리**:
    - **실제 값이 1일 때**: 예측값이 1에 가까울수록 오차는 0에 수렴하고, 0에 가까워질수록 오차는 무한히 커진다. (`-log(h)`)
    - **실제 값이 0일 때**: 예측값이 0에 가까울수록 오차는 0에 수렴하고, 1에 가까워질수록 오차는 무한히 커진다. (`-log(1-h)`)
- **통합 공식**: `- { y * log(h) + (1 - y) * log(1-h) }`
- **구조**: 이진 분류에서는 출력층의 뉴런이 1개이며, 이 뉴런이 출력하는 양성 클래스에 대한 확률(h)만으로 양성 및 음성 클래스에 대한 오차를 모두 계산할 수 있다. (음성 클래스 확률 = 1-h)

#### 다중 교차 엔트로피 (Categorical & Sparse Categorical Cross-Entropy)

다중 분류 문제에서는 출력층의 뉴런이 클래스의 수만큼 존재하며, 각 뉴런은 해당 클래스에 대한 확률을 출력한다. 교차 엔트로피는 타깃 클래스에 해당하는 확률값만을 사용하여 오차를 계산한다.

- **원-핫 인코딩 (One-hot Encoding)**: 타깃값을 특정 클래스에 해당하는 인덱스만 1이고 나머지는 모두 0인 벡터로 변환하는 방식. 예를 들어, '티셔츠'(클래스 0)의 타깃값은 `[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]`가 된다.

다중 분류의 손실 함수는 타깃값의 형태에 따라 두 종류로 나뉜다.

|   |   |   |
|---|---|---|
|오차 함수 종류|타깃값 형태|설명|
|**범주형 교차 엔트로피 (Categorical Cross-Entropy)**|원-핫 인코딩 형태|모델의 예측 확률 분포와 원-핫 인코딩된 실제 레이블 간의 차이를 계산한다. 이 손실 함수를 사용하려면 타깃 데이터를 반드시 원-핫 인코딩으로 변환해야 한다.|
|**희소 범주형 교차 엔트로피 (Sparse Categorical Cross-Entropy)**|정수값 형태|타깃값이 `0`, `1`, `2`와 같은 정수 형태일 때 사용 가능하다. 텐서플로(TensorFlow)와 같은 프레임워크는 내부적으로 정수 레이블을 처리해주므로, 별도의 원-핫 인코딩 과정이 필요 없어 편리하다.|

## 3. 인공 신경망 및 심층 신경망 구축

### 신경망의 기본 구조와 클래스

- **밀집층 (Dense Layer)**: 한 층의 모든 뉴런이 다음 층의 모든 뉴런과 완전하게 연결된 층. '완전 연결층(Fully Connected Layer)'이라고도 불린다.
- **Flatten 클래스**: 다차원 배열 형태의 입력 데이터(예: 28x28 이미지)를 1차원 배열(예: 784개 요소)로 평탄화하는 역할을 하는 층. 주로 입력층과 첫 번째 은닉층 사이에 위치하여 이미지 데이터를 밀집층이 처리할 수 있는 형태로 변환한다. `model.summary()`에서 입력값의 차원을 명확히 확인할 수 있는 장점이 있다.

### 모델 구조 정의 방법

케라스(Keras)에서는 `Sequential` API를 사용하여 층을 순차적으로 쌓아 모델을 간단하게 정의할 수 있으며, 주로 세 가지 방법이 사용된다.

1. **층 객체 생성 후 모델에 전달**: `Dense` 클래스로 각 층을 미리 생성한 후, `Sequential` 클래스의 생성자에 리스트 형태로 전달한다.
2. **모델 생성 시 층 정의**: `Sequential` 클래스의 생성자 내에서 직접 `Dense` 객체를 정의하여 전달한다. 각 층에 이름을 부여할 수 있어 가독성을 높일 수 있다.
3. `**add()**` **메서드 활용**: 빈 `Sequential` 객체를 먼저 생성한 후, `model.add()` 메서드를 호출하여 층을 순서대로 추가한다. 동적으로 층을 추가할 때 유용하다.

### 모델 컴파일 및 파라미터 확인

- **모델 컴파일 (**`**model.compile()**`**)**: 정의된 모델 구조가 효과적으로 학습될 수 있도록 환경을 설정하는 과정이다.
    - `**loss**`: 손실 함수를 지정한다. 패션 MNIST와 같이 정수 타깃값을 사용하는 다중 분류 문제에서는 `'sparse_categorical_crossentropy'`를 사용한다.
    - `**metrics**`: 훈련 및 검증 과정에서 모델의 성능을 평가할 지표를 설정한다. 분류 문제에서는 보통 `'accuracy'`(정확도)를 사용한다.
- **모델 요약 (**`**model.summary()**`**)**: 생성된 모델의 전체 구조를 확인하는 기능이다.
    - 각 층의 이름, 클래스, 출력 형태(Output Shape), 그리고 파라미터(학습 가능한 가중치와 편향) 수를 보여준다.
    - 이를 통해 모델의 복잡도와 구조를 한눈에 파악할 수 있다.