
## Executive Summary

본 문서는 데이터 과학 모델 개발의 핵심 과제인 **모델 평가 및 개선**에 관한 핵심 원칙과 방법론을 종합적으로 설명한다. 모델 개발의 최종 목표는 훈련된 데이터뿐만 아니라 이전에 접하지 않은 새로운 데이터에 대해서도 예측을 잘 수행하는 **일반화(Generalization) 성능**을 확보하는 것이다.

이를 위해 **표본 외(Out-of-Sample) 성능 검증**이 필수적이며, 이는 전체 데이터를 **훈련(Training) 데이터**와 **테스트(Test) 데이터**로 분리하여 평가하는 방식으로 이루어진다. 그러나 단순한 데이터 분할은 모델 성능 측정의 신뢰성(정밀도) 문제를 야기할 수 있으며, 이를 해결하기 위해 **교차 검증(Cross-Validation)**이 효과적인 대안으로 사용된다. 교차 검증은 데이터를 여러 부분(fold)으로 나누어 반복적으로 평가하고 결과를 평균함으로써 한정된 데이터를 효율적으로 활용하고 안정적인 성능 지표를 도출한다.

모델 개발 과정에서는 모델이 훈련 데이터의 노이즈까지 학습하여 새로운 데이터에 대한 성능이 저하되는 **과적합(Overfitting)**과, 데이터의 패턴을 충분히 학습하지 못하는 **과소적합(Underfitting)** 사이의 균형을 맞추는 것이 중요하다. 이는 모델의 복잡도(용량)를 조절함으로써 달성할 수 있다.

과적합을 방지하기 위한 주요 기법으로 **정규화(Regularization)**가 있으며, 대표적인 예가 **리지 회귀(Ridge Regression)**이다. 리지 회귀는 모델의 가중치(파라미터)가 과도하게 커지는 것을 제어하여 모델의 복잡도를 낮추고 일반화 성능을 향상시킨다. 이때 정규화의 강도를 조절하는 `alpha` 값과 같은 **하이퍼파라미터**를 최적화하는 과정이 필요하며, **그리드 서치(Grid Search)**는 가능한 하이퍼파라미터 조합을 체계적으로 탐색하는 전통적인 방법이다.

궁극적으로, 신뢰할 수 있는 모델을 개발하고 평가하기 위해서는 **훈련, 검증(Validation), 테스트 데이터셋**의 역할을 명확히 구분하고 올바른 절차에 따라 활용하는 것이 매우 중요하다.

--------------------------------------------------------------------------------

## 1. 모델 일반화 성능 평가

모델의 진정한 가치는 훈련 데이터에 대한 성능이 아닌, 실제 환경의 새로운 데이터에 대한 예측 능력, 즉 **일반화 성능**에 있다.

### 1.1. 표본 외 성능의 중요성

- **표본 내(In-sample) 성능 평가의 한계**: 훈련 시 사용한 데이터로 모델을 평가하면 모델의 적합도는 알 수 있으나, 신규 데이터에 대한 성능은 보장할 수 없다. 이는 모델 개발의 최종 목표인 일반화 성능 향상에 부합하지 않는다.
- **일반화 오류(Generalization Error)**: 모델이 이전에 관찰되지 않은 데이터에 대해 얼마나 잘 수행하는지를 측정하는 지표. 이 오류를 최소화하는 것이 목표이다.
- **표본 외(Out-of-Sample) 성능 검증**: 일반화 성능을 근사하기 위해 필수적인 절차로, 모델이 한 번도 보지 못한 데이터를 사용하여 평가한다.

### 1.2. 데이터 분할을 통한 평가

- **기본 접근법**: 보유한 데이터를 **훈련 데이터**와 **테스트 데이터**로 분리한다. 일반적으로 7:3 또는 8:2 비율이 사용된다.
    - **훈련 데이터**: 모델을 학습시키는 데 사용된다.
    - **테스트 데이터**: 학습이 완료된 모델의 최종 일반화 성능을 평가하는 데 사용된다.
- **정확도(Accuracy)와 정밀도(Precision)의 트레이드오프**:
    - **훈련 데이터 비중이 높은 경우 (예: 9:1)**: 모델 자체의 학습은 충실하게 이루어져 **정확도(타당성)**는 높아질 수 있으나, 소량의 테스트 데이터로 인한 평가 결과의 변동성이 커져 성능 측정의 **정밀도(신뢰성)**가 저하된다.
    - **테스트 데이터 비중이 높은 경우**: 평가의 정밀도는 높아지지만, 훈련 데이터 부족으로 모델이 제대로 학습되지 않아 **정확도** 자체가 떨어져 의미 없는 평가가 될 수 있다.

### 1.3. 교차 검증 (Cross-Validation)

교차 검증은 데이터 분할 방식의 한계를 극복하고, 주어진 데이터를 최대한 효율적으로 활용하여 모델 성능 측정의 신뢰성을 높이는 기법이다.

- **핵심 아이디어**: 테스트셋을 하나로 고정하지 않고, 데이터의 여러 부분을 번갈아 가며 테스트셋으로 활용한다.
- **K-Fold 교차 검증 절차**:
    1. 전체 데이터를 K개의 동일한 크기의 부분집합(fold)으로 나눈다.
    2. 첫 번째 fold를 테스트셋으로 사용하고, 나머지 K-1개의 fold를 훈련셋으로 사용하여 모델을 학습하고 평가한다.
    3. 두 번째 fold를 테스트셋으로 사용하는 등, 모든 fold가 한 번씩 테스트셋으로 사용될 때까지 K번의 평가를 반복한다.
    4. K개의 평가 점수(예: MSE, R²)를 평균하여 최종 모델 성능 지표로 삼는다.

## 2. 모델 용량과 과적합 문제

모델의 성능은 데이터의 복잡성과 모델의 복잡성(용량) 간의 관계에 크게 좌우된다.

### 2.1. 과소적합과 과적합

- **과소적합 (Underfitting)**
    - **정의**: 모델이 너무 단순하여 데이터에 내재된 패턴을 충분히 학습하지 못하는 상태. (데이터 > 모델 용량)
    - **특징**: **편향(Bias)**이 높다. 훈련 데이터에 대한 오차(Training Error)와 테스트 데이터에 대한 오차(Test Error)가 모두 높게 나타난다.
- **과적합 (Overfitting)**
    - **정의**: 모델이 훈련 데이터에 과도하게 최적화되어 데이터의 실제 패턴뿐만 아니라 노이즈까지 학습한 상태. (데이터 < 모델 용량)
    - **특징**: **분산(Variance)**이 높다. 훈련 오차는 매우 낮지만, 새로운 데이터에 대한 테스트 오차는 매우 크게 나타난다.
- **최적의 모델**: 편향과 분산이 균형을 이루는 지점으로, "Just right" 상태의 모델이다.

### 2.2. 모델 복잡도 선택

모델의 복잡도를 조절하여 과소적합과 과적합을 피하고 최적의 모델을 선택해야 한다.

|   |   |   |   |
|---|---|---|---|
|모델 복잡도|훈련 오차 (Training Error)|테스트 오차 (Test Error)|상태|
|낮음|높음|높음|과소적합|
|**적정**|낮음|**최소**|**최적 모델**|
|높음|매우 낮음|높음|과적합|

- **판단 기준**: 훈련 오차는 지속적으로 감소하는 경향을 보이지만, 테스트 오차는 감소하다가 특정 지점에서 다시 증가한다. **테스트 오차가 최소가 되는 지점**의 모델 복잡도를 선택하는 것이 일반화 성능을 극대화하는 방법이다.
- **부적절한 모델 선택**: 만약 데이터의 실제 패턴(True Function)과 전혀 다른 종류의 모델(예: 사인 함수 형태 데이터에 다항 회귀 적용)을 선택하면, 복잡도를 아무리 조절해도 좋은 성능을 얻을 수 없다.

## 3. 과적합 방지 기법: 정규화와 리지 회귀

과적합을 제어하기 위해 모델의 복잡도에 제약을 가하는 기법을 **정규화(Regularization)**라고 한다.

### 3.1. 리지 회귀 (Ridge Regression)

리지 회귀는 L2 정규화라고도 불리며, 과적합을 방지하는 대표적인 회귀 모델이다.

- **작동 원리**: 손실 함수(Loss Function)에 가중치들의 제곱합에 비례하는 페널티 항을 추가한다. 이를 통해 모델은 오차를 최소화하는 동시에 가중치(회귀 계수)의 크기도 작게 유지하려고 노력한다.
    - 최소화 목표: `(실제값 - 예측값)²의 합` + `α * (가중치들의 제곱합)`
- **효과**:
    - 가중치들의 절대값을 작게 만들어 특정 피처(Feature)가 모델에 미치는 영향력을 줄인다.
    - 피처를 제거하지 않으면서도 모델의 복잡도를 효과적으로 감소시킨다.
    - 특히 고차항의 영향력을 약화시켜 과적합을 방지한다.
- **알파(Alpha)**: 정규화의 강도를 조절하는 **하이퍼파라미터**이다.
    - `alpha`가 0에 가까우면 일반적인 회귀 모델과 유사해진다.
    - `alpha`가 커질수록 가중치들은 0에 가깝게 수축되어 모델이 더 단순해진다.

## 4. 최적 모델 탐색: 하이퍼파라미터 튜닝

모델의 성능을 극대화하기 위해서는 최적의 하이퍼파라미터 조합을 찾는 과정이 필수적이다.

### 4.1. 파라미터와 하이퍼파라미터

|   |   |   |
|---|---|---|
|구분|파라미터 (Parameter)|하이퍼파라미터 (Hyperparameter)|
|**정의**|훈련 과정에서 데이터로부터 학습되는 값|모델 학습 전에 사용자가 직접 설정하는 값|
|**예시**|회귀 모델의 계수(가중치)|리지 회귀의 `alpha` 값, 학습률, 다항식 차수|
|**설정 방식**|자동 생성|수동 지정 및 튜닝|

### 4.2. 그리드 서치 (Grid Search)

그리드 서치는 하이퍼파라미터 최적화(HPO)를 위한 전통적이고 체계적인 탐색 방법이다.

- **탐색 방식**: 사용자가 지정한 하이퍼파라미터 값들의 모든 조합에 대해 모델을 학습하고 성능을 평가한다.
- **성능 평가**: 각 조합의 성능을 평가할 때는 주로 **교차 검증**을 함께 사용하여 신뢰도를 높인다.
- **장단점**:
    - **장점**: 지정된 범위 내에서 최상의 하이퍼파라미터 조합을 찾을 수 있다.
    - **단점**: 탐색해야 할 조합의 수가 많아지면 시간이 매우 오래 걸린다.

## 5. 데이터셋의 역할과 활용

정확하고 신뢰성 있는 모델 개발 및 평가를 위해서는 데이터셋을 목적에 맞게 명확히 구분하여 사용해야 한다.

### 5.1. 데이터셋의 3가지 유형

1. **훈련 데이터 (Training Set)**
    - **역할**: 모델을 학습시켜 파라미터를 적합(fit)시키는 데 사용된다.
2. **검증 데이터 (Validation Set)**
    - **역할**: 학습된 여러 모델(서로 다른 하이퍼파라미터를 가진)의 성능을 비교하여 최적의 하이퍼파라미터를 선택하는 데 사용된다. Dev Set 또는 Hold-out Set이라고도 한다.
3. **테스트 데이터 (Test Set)**
    - **역할**: 최종적으로 선택된 모델의 일반화 성능을 단 한 번 평가하여 최종 성능 지표를 산출하는 데 사용된다. 이 데이터는 모델 튜닝 과정에 절대 관여해서는 안 된다.

### 5.2. 올바른 활용 워크플로우

|   |   |   |   |
|---|---|---|---|
|단계|수행 작업|사용 데이터셋|사용 여부|
|**1. 초기 모델링**|모델 학습|훈련 데이터|O|
|**2. 하이퍼파라미터 튜닝**|다양한 하이퍼파라미터로 학습된 모델들의 성능 비교 및 최적 조합 선택|검증 데이터|O|
|**3. 최종 성능 평가**|선택된 최종 모델의 일반화 성능 측정|테스트 데이터|X|

- **교차 검증과 데이터셋**: 교차 검증을 수행할 때, 머신러닝 라이브러리는 내부적으로 훈련 데이터를 다시 훈련용과 임시 검증용으로 나누어 하이퍼파라미터 튜닝을 진행한다. 이로 인해 실제로는 검증 데이터와 테스트 데이터가 혼용되어 사용되는 것처럼 보일 수 있으나, 개념적으로는 명확히 구분해야 한다.